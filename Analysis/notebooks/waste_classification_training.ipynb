{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç AI Waste Classification System\n",
    "## Exploratory Data Analysis & Model Training\n",
    "\n",
    "**Workshop**: Green Skilling & AI for Sustainability\n",
    "\n",
    "**Objective**: Build a CNN model to classify waste into Organic and Recyclable categories\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning & Computer Vision\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "# Utilities\n",
    "from pathlib import Path\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"‚úì TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"‚úì GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path\n",
    "DATA_DIR = 'data/DATASET'\n",
    "\n",
    "# Count images in each class\n",
    "data_path = Path(DATA_DIR)\n",
    "class_counts = {}\n",
    "\n",
    "for class_dir in data_path.iterdir():\n",
    "    if class_dir.is_dir():\n",
    "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png'))\n",
    "        class_name = 'Organic' if class_dir.name == 'O' else 'Recyclable'\n",
    "        class_counts[class_name] = len(images)\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name:15s}: {count:5d} images\")\n",
    "print(f\"{'Total':15s}: {sum(class_counts.values()):5d} images\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar plot\n",
    "colors = ['#2E7D32', '#FF6F00']\n",
    "ax[0].bar(class_counts.keys(), class_counts.values(), color=colors, alpha=0.8)\n",
    "ax[0].set_title('Class Distribution', fontsize=16, fontweight='bold')\n",
    "ax[0].set_ylabel('Number of Images', fontsize=12)\n",
    "ax[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "ax[1].pie(class_counts.values(), labels=class_counts.keys(), autopct='%1.1f%%',\n",
    "         colors=colors, startangle=90, textprops={'fontsize': 12})\n",
    "ax[1].set_title('Class Proportion', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nClass Balance Ratio: {max(class_counts.values()) / min(class_counts.values()):.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è 3. Sample Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "fig.suptitle('Sample Waste Images', fontsize=20, fontweight='bold')\n",
    "\n",
    "for idx, class_dir in enumerate(data_path.iterdir()):\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "    \n",
    "    class_name = 'Organic' if class_dir.name == 'O' else 'Recyclable'\n",
    "    images = list(class_dir.glob('*.jpg'))[:5]\n",
    "    \n",
    "    for i, img_path in enumerate(images):\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        axes[idx, i].imshow(img)\n",
    "        axes[idx, i].axis('off')\n",
    "        axes[idx, i].set_title(f\"{class_name}\\n{img_path.name}\", \n",
    "                              fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 4. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"\\nClass indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è 5. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with transfer learning\n",
    "def build_model():\n",
    "    # Load pre-trained MobileNetV2\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=(*IMG_SIZE, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build custom head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ], name='Waste_Classifier')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = build_model()\n",
    "\n",
    "# Display architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model architecture\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model_architecture.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    dpi=150\n",
    ")\n",
    "\n",
    "from IPython.display import Image\n",
    "Image('model_architecture.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 6. Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall'),\n",
    "        keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"‚úì Model compiled successfully!\")\n",
    "print(\"\\nOptimizer: Adam (lr=0.001)\")\n",
    "print(\"Loss: Binary Cross-Entropy\")\n",
    "print(\"Metrics: Accuracy, Precision, Recall, AUC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèãÔ∏è 7. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"‚úì Callbacks configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "EPOCHS = 25\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà 8. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Training History', fontsize=20, fontweight='bold')\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 0].plot(history.history['accuracy'], label='Training', linewidth=2)\n",
    "axes[0, 0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Accuracy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[0, 1].plot(history.history['loss'], label='Training', linewidth=2)\n",
    "axes[0, 1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Precision\n",
    "axes[1, 0].plot(history.history['precision'], label='Training', linewidth=2)\n",
    "axes[1, 0].plot(history.history['val_precision'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_title('Precision', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Precision')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Recall\n",
    "axes[1, 1].plot(history.history['recall'], label='Training', linewidth=2)\n",
    "axes[1, 1].plot(history.history['val_recall'], label='Validation', linewidth=2)\n",
    "axes[1, 1].set_title('Recall', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Recall')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 9. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"Evaluating model on validation set...\\n\")\n",
    "\n",
    "results = model.evaluate(val_generator, verbose=1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Loss:      {results[0]:.4f}\")\n",
    "print(f\"Accuracy:  {results[1]:.4f} ({results[1]*100:.2f}%)\")\n",
    "print(f\"Precision: {results[2]:.4f}\")\n",
    "print(f\"Recall:    {results[3]:.4f}\")\n",
    "print(f\"AUC:       {results[4]:.4f}\")\n",
    "\n",
    "# Calculate F1-Score\n",
    "f1 = 2 * (results[2] * results[3]) / (results[2] + results[3])\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "val_generator.reset()\n",
    "y_pred_probs = model.predict(val_generator, verbose=1)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Classification report\n",
    "class_names = ['Organic', 'Recyclable']\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(report)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=class_names,\n",
    "           yticklabels=class_names,\n",
    "           cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print confusion matrix values\n",
    "print(\"\\nConfusion Matrix Values:\")\n",
    "print(f\"True Negatives (Organic):  {cm[0, 0]}\")\n",
    "print(f\"False Positives:           {cm[0, 1]}\")\n",
    "print(f\"False Negatives:           {cm[1, 0]}\")\n",
    "print(f\"True Positives (Recycl.):  {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ 10. Sample Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample images\n",
    "val_generator.reset()\n",
    "sample_batch = next(val_generator)\n",
    "sample_images = sample_batch[0][:9]\n",
    "sample_labels = sample_batch[1][:9]\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(sample_images)\n",
    "\n",
    "# Plot predictions\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.suptitle('Sample Predictions', fontsize=20, fontweight='bold')\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    # Display image\n",
    "    ax.imshow(sample_images[idx])\n",
    "    \n",
    "    # Get prediction\n",
    "    pred_class = 'Recyclable' if predictions[idx] > 0.5 else 'Organic'\n",
    "    true_class = 'Recyclable' if sample_labels[idx] == 1 else 'Organic'\n",
    "    confidence = predictions[idx][0] if predictions[idx] > 0.5 else 1 - predictions[idx][0]\n",
    "    \n",
    "    # Set title color based on correctness\n",
    "    color = 'green' if pred_class == true_class else 'red'\n",
    "    \n",
    "    ax.set_title(\n",
    "        f\"True: {true_class}\\nPred: {pred_class}\\nConf: {confidence*100:.1f}%\",\n",
    "        fontsize=12,\n",
    "        color=color,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ 11. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in multiple formats\n",
    "\n",
    "# Format 1: Keras H5\n",
    "model.save('waste_classifier_final.h5')\n",
    "print(\"‚úì Saved: waste_classifier_final.h5\")\n",
    "\n",
    "# Format 2: TensorFlow SavedModel\n",
    "model.save('waste_classifier_savedmodel')\n",
    "print(\"‚úì Saved: waste_classifier_savedmodel/\")\n",
    "\n",
    "# Format 3: TensorFlow Lite (for mobile/edge)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('waste_classifier.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"‚úì Saved: waste_classifier.tflite\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL MODELS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ 12. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n‚úì Dataset: {train_generator.samples + val_generator.samples} images\")\n",
    "print(f\"‚úì Classes: Organic, Recyclable\")\n",
    "print(f\"‚úì Model: MobileNetV2 with Transfer Learning\")\n",
    "print(f\"‚úì Training Accuracy: {history.history['accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"‚úì Validation Accuracy: {results[1]*100:.2f}%\")\n",
    "print(f\"‚úì F1-Score: {f1:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. Test predictions: python predict.py --mode image --image test.jpg\")\n",
    "print(\"2. Real-time webcam: python predict.py --mode webcam\")\n",
    "print(\"3. Launch web app: streamlit run app.py\")\n",
    "print(\"4. Deploy to cloud or edge device\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ôªÔ∏è READY TO MAKE A DIFFERENCE! üåç\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
